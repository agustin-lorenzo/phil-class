{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e1e1a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn import preprocessing\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30fdd1d",
   "metadata": {},
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cfbae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Absurd Reasoning Absurdity and Suicide Ther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>passion of living) there are probably but two ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that very day addressed him indifferently. He ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this relationship between the absurd and suici...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peregrinos who is born of legend, m and Jules ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>any meaning? If this world had been created by...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>our own pleasures and find fulfilment and happ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>our lives it is not enough to go beyond psycho...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>to take matters into his own hands and arrange...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>Nagel's argument for the rationality of altrui...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     An Absurd Reasoning Absurdity and Suicide Ther...       0\n",
       "1     passion of living) there are probably but two ...       0\n",
       "2     that very day addressed him indifferently. He ...       0\n",
       "3     this relationship between the absurd and suici...       0\n",
       "4     Peregrinos who is born of legend, m and Jules ...       0\n",
       "...                                                 ...     ...\n",
       "2587  any meaning? If this world had been created by...       4\n",
       "2588  our own pleasures and find fulfilment and happ...       4\n",
       "2589  our lives it is not enough to go beyond psycho...       4\n",
       "2590  to take matters into his own hands and arrange...       4\n",
       "2591  Nagel's argument for the rationality of altrui...       4\n",
       "\n",
       "[2592 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data.csv\", index_col=0)\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['labels'] = label_encoder.fit_transform(df['labels'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f15349",
   "metadata": {},
   "source": [
    "## Creating train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ac5ef",
   "metadata": {},
   "source": [
    "Loading the model and tokenizer, checking input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5273b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 100/100 [00:00<00:00, 1176.84it/s, Materializing param=distilbert.transformer.layer.5.sa_layer_norm.weight]   \n",
      "DistilBertForSequenceClassification LOAD REPORT from: distilbert-base-uncased\n",
      "Key                     | Status     | \n",
      "------------------------+------------+-\n",
      "vocab_projector.bias    | UNEXPECTED | \n",
      "vocab_transform.bias    | UNEXPECTED | \n",
      "vocab_layer_norm.weight | UNEXPECTED | \n",
      "vocab_transform.weight  | UNEXPECTED | \n",
      "vocab_layer_norm.bias   | UNEXPECTED | \n",
      "pre_classifier.bias     | MISSING    | \n",
      "classifier.weight       | MISSING    | \n",
      "pre_classifier.weight   | MISSING    | \n",
      "classifier.bias         | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input='An Absurd Reasoning Absurdity and Suicide There is but one truly serious philosophical problem, and that is suicide. Judging whether life is or is not worth living amounts to answering the fundamental question of philosophy. All the rest— whether or not the world has three dimensions, whether the mind has nine or twelve categories—comes afterwards. These are games; one must first answer. And if it is true, as Nietzsche claims, that a philosopher, to deserve our respect, must preach by example, you can appreciate the importance of that reply, for it will precede the definitive act. These are facts the heart can feel; yet they call for careful study before they become clear to the intellect. If I ask myself how to judge that this question is more urgent than that, I reply that one judges by the actions it entails. I have never seen anyone die for the ontologi-cal argument. Galileo, who held a scientific truth of great importance, abjured it with the greatest ease as soon as it endangered his life. In a certain sense, he did rightThat truth was not worth the stake. Whether the earth or the sun revolves around the other is a matter of profound indifference. To tell the truth, it is a futile question. On the other hand, I see many people die because they judge that life is not worth living. I see others paradoxically getting killed for the ideas or illusions that give them a reason for living (what is called a reason for living is also an excellent reason for dying). I therefore conclude that the meaning of life is the most urgent of questions. How to answer it? On all essential problems (I mean thereby those that run the risk of leading to death or those that intensify the'\n",
      "\n",
      "encoded_input={'input_ids': tensor([[  101,  2019, 18691, 13384, 18691,  3012,  1998,  5920,  2045,  2003,\n",
      "          2021,  2028,  5621,  3809,  9569,  3291,  1010,  1998,  2008,  2003,\n",
      "          5920,  1012, 13325,  3251,  2166,  2003,  2030,  2003,  2025,  4276,\n",
      "          2542,  8310,  2000, 10739,  1996,  8050,  3160,  1997,  4695,  1012,\n",
      "          2035,  1996,  2717,  1517,  3251,  2030,  2025,  1996,  2088,  2038,\n",
      "          2093,  9646,  1010,  3251,  1996,  2568,  2038,  3157,  2030,  4376,\n",
      "          7236,  1517,  3310,  5728,  1012,  2122,  2024,  2399,  1025,  2028,\n",
      "          2442,  2034,  3437,  1012,  1998,  2065,  2009,  2003,  2995,  1010,\n",
      "          2004, 28898,  4447,  1010,  2008,  1037,  9667,  1010,  2000, 10107,\n",
      "          2256,  4847,  1010,  2442, 25250,  2011,  2742,  1010,  2017,  2064,\n",
      "          9120,  1996,  5197,  1997,  2008,  7514,  1010,  2005,  2009,  2097,\n",
      "          3653, 22119,  1996, 15764,  2552,  1012,  2122,  2024,  8866,  1996,\n",
      "          2540,  2064,  2514,  1025,  2664,  2027,  2655,  2005,  6176,  2817,\n",
      "          2077,  2027,  2468,  3154,  2000,  1996, 24823,  1012,  2065,  1045,\n",
      "          3198,  2870,  2129,  2000,  3648,  2008,  2023,  3160,  2003,  2062,\n",
      "         13661,  2084,  2008,  1010,  1045,  7514,  2008,  2028,  6794,  2011,\n",
      "          1996,  4506,  2009,  4372, 22081,  1012,  1045,  2031,  2196,  2464,\n",
      "          3087,  3280,  2005,  1996,  3031, 21197,  2072,  1011, 10250,  6685,\n",
      "          1012, 21514,  1010,  2040,  2218,  1037,  4045,  3606,  1997,  2307,\n",
      "          5197,  1010, 11113, 26949,  2009,  2007,  1996,  4602,  7496,  2004,\n",
      "          2574,  2004,  2009, 10193,  2010,  2166,  1012,  1999,  1037,  3056,\n",
      "          3168,  1010,  2002,  2106,  2157,  8322,  2102,  3606,  2001,  2025,\n",
      "          4276,  1996,  8406,  1012,  3251,  1996,  3011,  2030,  1996,  3103,\n",
      "         19223,  2105,  1996,  2060,  2003,  1037,  3043,  1997, 13769, 25920,\n",
      "          1012,  2000,  2425,  1996,  3606,  1010,  2009,  2003,  1037, 24495,\n",
      "          3160,  1012,  2006,  1996,  2060,  2192,  1010,  1045,  2156,  2116,\n",
      "          2111,  3280,  2138,  2027,  3648,  2008,  2166,  2003,  2025,  4276,\n",
      "          2542,  1012,  1045,  2156,  2500, 20506, 15004,  2893,  2730,  2005,\n",
      "          1996,  4784,  2030, 24883,  2008,  2507,  2068,  1037,  3114,  2005,\n",
      "          2542,  1006,  2054,  2003,  2170,  1037,  3114,  2005,  2542,  2003,\n",
      "          2036,  2019,  6581,  3114,  2005,  5996,  1007,  1012,  1045,  3568,\n",
      "         16519,  2008,  1996,  3574,  1997,  2166,  2003,  1996,  2087, 13661,\n",
      "          1997,  3980,  1012,  2129,  2000,  3437,  2009,  1029,  2006,  2035,\n",
      "          6827,  3471,  1006,  1045,  2812,  8558,  2216,  2008,  2448,  1996,\n",
      "          3891,  1997,  2877,  2000,  2331,  2030,  2216,  2008, 20014,  6132,\n",
      "          8757,  1996,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "\n",
      "output=SequenceClassifierOutput(loss=None, logits=tensor([[-0.0569, -0.0087,  0.0130,  0.0078,  0.0303]],\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "label2id = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', \n",
    "                                                            num_labels=5,\n",
    "                                                            id2label=id2label,\n",
    "                                                            label2id=label2id)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "input = df['text'][0]\n",
    "encoded_input = tokenizer(input, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "print(f\"\\n{input=}\")\n",
    "print(f\"\\n{encoded_input=}\")\n",
    "print(f\"\\n{output=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa0e42d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2073/2073 [00:00<00:00, 5323.70 examples/s]\n",
      "Map: 100%|██████████| 519/519 [00:00<00:00, 6419.15 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2073\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 519\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_text, y_train, y_text = train_test_split(df['entry'], df['label'], test_size=0.2, random_state=42)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True)\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "218e9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ec52f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agustinlorenzjo/Developer/phil-class/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1820' max='5200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1820/5200 26:20 < 48:58, 1.15 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.066302</td>\n",
       "      <td>0.982790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.208968</td>\n",
       "      <td>0.090043</td>\n",
       "      <td>0.979822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208968</td>\n",
       "      <td>0.015549</td>\n",
       "      <td>0.998067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>0.996152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.998076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>0.996154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>0.994221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s]\n",
      "/Users/agustinlorenzjo/Developer/phil-class/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "/Users/agustinlorenzjo/Developer/phil-class/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "/Users/agustinlorenzjo/Developer/phil-class/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "/Users/agustinlorenzjo/Developer/phil-class/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "/Users/agustinlorenzjo/Developer/phil-class/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s]\n",
      "/Users/agustinlorenzjo/Developer/phil-class/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
      "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('model/tokenizer_config.json', 'model/tokenizer.json')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=20,\n",
    "    learning_rate=2e-5,\n",
    "    optim='stable_adamw',\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model('model')\n",
    "tokenizer.save_pretrained('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee22208e",
   "metadata": {},
   "source": [
    "Test model trained successfully! Before adjusting any hyperparameters for improving performance, accuracy seems to be a little above 50% (better than expected accuracy of a random guesser, 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8431568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 104/104 [00:00<00:00, 1108.28it/s, Materializing param=pre_classifier.weight]                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_absurd = [{'label': 'absurdism', 'score': 0.9986805319786072}]\n",
      "pred_exist = [{'label': 'existentialism', 'score': 0.9835440516471863}]\n",
      "pred_stoic = [{'label': 'absurdism', 'score': 0.9937043786048889}]\n",
      "pred_util = [{'label': 'utilitarianism', 'score': 0.998670220375061}]\n",
      "pred_epi = [{'label': 'absurdism', 'score': 0.9503107666969299}]\n"
     ]
    }
   ],
   "source": [
    "absurdism = \"The absurd is the conflict between the rational mind and the irrational world. But one must imagine Sisyphus happy.\"\n",
    "existentialism = \"Man is condemned to be free; because once thrown into the world, he is responsible for everything he does. It is up to you to give life a meaning. To choose to be this or that is to affirm at the same time the value of what we choose.\"\n",
    "stoicism = \"You have power over your mind—not outside events. Realize this, and you will find strength. Everything we hear is an opinion, not a fact. Everything we see is a perspective, not the truth. The happiness of your life depends upon the quality of your thoughts.\"\n",
    "util = \"argument for preferring the life of a human being to that of an animal (with which most modern readers would be quite comfortable) is exactly paralleled by his argument for preferring the life of an intelligent human being to that of fool.\"\n",
    "epi = \"the possession of those instruments whereby the male with female can unite, the one with other in mutual ravishments. And in the ages after monsters died, perforce there perished many a stock, unable by propagation to forge a progeny.\"\n",
    "\n",
    "pipe = pipeline('text-classification', 'model')\n",
    "pred_absurd = pipe(absurdism)\n",
    "pred_exist = pipe(existentialism)\n",
    "pred_stoic = pipe(stoicism)\n",
    "pred_util = pipe(util)\n",
    "pred_epi = pipe(epi)\n",
    "\n",
    "print(f\"{pred_absurd = }\")\n",
    "print(f\"{pred_exist = }\")\n",
    "print(f\"{pred_stoic = }\")\n",
    "print(f\"{pred_util = }\")\n",
    "print(f\"{pred_epi = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48e2b3",
   "metadata": {},
   "source": [
    "Correctly guessed absurdism and existentialism!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39596523",
   "metadata": {},
   "source": [
    "## Creating a UI for the model with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23839d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict(text):\n",
    "    return pipe(text)[0][\"label\"]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\"text\"],\n",
    "    outputs=[\"text\"],\n",
    "    api_name=\"predict\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
